{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alenadamyan/Documents/AUA/moviescripts/moviescripts/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StarWars\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../data/raw/StarWarsEpisodes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_ep4 = os.path.join(base_dir,\"SW_EpisodeIV.txt\")\n",
    "folder_ep5 = os.path.join(base_dir,\"SW_EpisodeV.txt\")\n",
    "folder_ep6 = os.path.join(base_dir,\"SW_EpisodeVI.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ep4 = pd.read_csv(folder_ep4, sep =' ', header=0, escapechar='\\\\')\n",
    "df_ep5 = pd.read_csv(folder_ep5, sep =' ', header=0, escapechar='\\\\')\n",
    "df_ep6 = pd.read_csv(folder_ep6, sep =' ', header=0, escapechar='\\\\')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>Did you hear that?  They've shut down the main...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>We're doomed!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>There'll be no escape for the Princess this time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>What's that?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>I should have known better than to trust the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>LUKE</td>\n",
       "      <td>Oh, no!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>Oh, my!  Artoo!  Can you hear me?  Say somethi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>TECHNICIAN</td>\n",
       "      <td>We'll get to work on him right away.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>THREEPIO</td>\n",
       "      <td>You must repair him!  Sir, if any of my circui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>LUKE</td>\n",
       "      <td>He'll be all right.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       character                                           dialogue\n",
       "1       THREEPIO  Did you hear that?  They've shut down the main...\n",
       "2       THREEPIO                                      We're doomed!\n",
       "3       THREEPIO  There'll be no escape for the Princess this time.\n",
       "4       THREEPIO                                       What's that?\n",
       "5       THREEPIO  I should have known better than to trust the l...\n",
       "...          ...                                                ...\n",
       "1006        LUKE                                            Oh, no!\n",
       "1007    THREEPIO  Oh, my!  Artoo!  Can you hear me?  Say somethi...\n",
       "1008  TECHNICIAN               We'll get to work on him right away.\n",
       "1009    THREEPIO  You must repair him!  Sir, if any of my circui...\n",
       "1010        LUKE                                He'll be all right.\n",
       "\n",
       "[1010 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ep4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.concat([df_ep4['character'],df_ep5['character'],df_ep6['character']]).tolist()\n",
    "X = pd.concat([df_ep4['dialogue'],df_ep5['dialogue'],df_ep6['dialogue']]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.unique(Y)\n",
    "label_count = [sum(i == np.array(Y)) for i in labels]\n",
    "for i,(a,b) in enumerate(zip(labels,label_count)):\n",
    "    if b < 10:\n",
    "        labels[i] = \"Other\"\n",
    "labels = np.unique(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ACKBAR', 'BEN', 'BIGGS', 'COMMANDER', 'CREATURE', 'EMPEROR',\n",
       "       'GOLD LEADER', 'HAN', 'JABBA', 'LANDO', 'LEIA', 'LUKE', 'OFFICER',\n",
       "       'OWEN', 'Other', 'PIETT', 'RED LEADER', 'RIEEKAN', 'TARKIN',\n",
       "       'THREEPIO', 'TROOPER', 'VADER', 'WEDGE', 'YODA'], dtype='<U30')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2ind = {i:j for i,j in zip(labels,range(len(labels)))}\n",
    "ind2char = {j:i for i,j in zip(labels,range(len(labels)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = X.copy()\n",
    "new_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(new_x)):\n",
    "    \n",
    "    if Y[idx] in labels:\n",
    "        label_point = char2ind[Y[idx]]\n",
    "    else:\n",
    "        label_point = char2ind[\"Other\"]\n",
    "    new_y.append(label_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sentence_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "    new_x = sentence_model.encode(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_names = movie_lines.iloc[:,0]\n",
    "# movie_names = movie_lines.iloc[:,1]\n",
    "# char_names = np.unique(list(set(char_names.values)))\n",
    "# movie_names = np.unique(list(set(movie_names.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomStarWarsDataset(Dataset):\n",
    "    def __init__(self, X, Y,transform=None, target_transform=None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.X[idx]\n",
    "\n",
    "        label_point = self.Y[idx]\n",
    "\n",
    "        # print(\"data_point is:\",data_point)\n",
    "        # print(\"label_point is:\",label_point)\n",
    "        # 768 \n",
    "        # print(sentence_encoded,label_point)\n",
    "        return data_point, label_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2523"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSentenceClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertSentenceClassifier, self).__init__()\n",
    "        self.dropout_rate = .5\n",
    "        self.lin1 = nn.Linear(768,256)\n",
    "        self.lin_layers = nn.ModuleList([nn.Linear(256,256) for i in range(4)])\n",
    "\n",
    "\n",
    "        self.lin2 = nn.Linear(256, len(labels))\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        x = nn.functional.relu(self.lin1(data))\n",
    "        x = nn.functional.dropout(x,self.dropout_rate)\n",
    "        for i in self.lin_layers:\n",
    "            x = nn.functional.relu(i(x))\n",
    "            x = nn.functional.dropout(x,self.dropout_rate)\n",
    "\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        x = nn.functional.softmax(x,dim = 1)\n",
    "\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train,x_test,y_train,y_test = train_test_split(new_x,new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier(max_leaf_nodes=25)\n",
    "# model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.score(x_train,y_train),model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomStarWarsDataset(new_x,new_y)\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [2000, 523])\n",
    "\n",
    "train_loader = DataLoader(train_set,batch_size=32,shuffle=True,drop_last=True)\n",
    "val_loader = DataLoader(val_set,batch_size=32,shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertSentenceClassifier()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Linear: 1-1                            196,864\n",
      "├─ModuleList: 1-2                        --\n",
      "|    └─Linear: 2-1                       65,792\n",
      "|    └─Linear: 2-2                       65,792\n",
      "|    └─Linear: 2-3                       65,792\n",
      "|    └─Linear: 2-4                       65,792\n",
      "├─Linear: 1-3                            6,168\n",
      "=================================================================\n",
      "Total params: 466,200\n",
      "Trainable params: 466,200\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Linear: 1-1                            196,864\n",
       "├─ModuleList: 1-2                        --\n",
       "|    └─Linear: 2-1                       65,792\n",
       "|    └─Linear: 2-2                       65,792\n",
       "|    └─Linear: 2-3                       65,792\n",
       "|    └─Linear: 2-4                       65,792\n",
       "├─Linear: 1-3                            6,168\n",
       "=================================================================\n",
       "Total params: 466,200\n",
       "Trainable params: 466,200\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    _, predictions = torch.max(preds, dim=1)\n",
    "    correct = (predictions == labels).sum().item()\n",
    "    return correct / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(device)\n\u001b[1;32m      3\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 1000\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(train_loader, total=len(train_loader))\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    num_batches = 0\n",
    "    for text, author_labels in loop:  # Assuming data_loader is set up to provide batches of data\n",
    "        data = text.to(device)\n",
    "        author_labels = author_labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        data = model(data)\n",
    "        # print(data.shape)\n",
    "        # print(\"data and author labels ::::: \",data,author_labels)\n",
    "        loss = nn.CrossEntropyLoss()(data,author_labels)\n",
    "        acc = accuracy(data, author_labels)\n",
    "\n",
    "        loss.backward()\n",
    "        running_loss += loss.item()\n",
    "        running_accuracy += acc\n",
    "        num_batches += 1\n",
    "\n",
    "        optimizer.step()\n",
    "        loop.set_description(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "     # Validation loop\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_running_accuracy = 0.0\n",
    "    val_num_batches = 0\n",
    "    with torch.no_grad():  # Disable gradient calculation during validation\n",
    "        for val_text, val_labels in val_loader:\n",
    "            val_data = val_text.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "\n",
    "            val_output = model(val_data)\n",
    "            val_acc = accuracy(val_output, val_labels)\n",
    "\n",
    "            val_running_accuracy += val_acc\n",
    "            val_num_batches += 1\n",
    "    avg_loss = running_loss / num_batches\n",
    "    avg_accuracy = running_accuracy / num_batches\n",
    "    val_avg_accuracy = val_running_accuracy / val_num_batches\n",
    "    print(f\"Validation Accuracy: {val_avg_accuracy:.4f} Accuracy: {avg_accuracy:.4f}\")\n",
    "    \n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moviescripts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57d255c94b3919c3b590e65021e667e868fc4932b6b03051f229d54b108b5f4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
